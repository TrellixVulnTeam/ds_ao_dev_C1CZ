{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b1193b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fe8ba579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_stock</th>\n",
       "      <th>product_avaliation</th>\n",
       "      <th>product_category</th>\n",
       "      <th>scrapy_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the_secret_garden</td>\n",
       "      <td>15.08</td>\n",
       "      <td>instock</td>\n",
       "      <td>4</td>\n",
       "      <td>classics</td>\n",
       "      <td>2022-05-05 15:36:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the_metamorphosis</td>\n",
       "      <td>28.58</td>\n",
       "      <td>instock</td>\n",
       "      <td>1</td>\n",
       "      <td>classics</td>\n",
       "      <td>2022-05-05 15:36:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_pilgrim's_progress</td>\n",
       "      <td>50.26</td>\n",
       "      <td>instock</td>\n",
       "      <td>2</td>\n",
       "      <td>classics</td>\n",
       "      <td>2022-05-05 15:36:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the_hound_of_the_baskervilles_(sherlock_holmes...</td>\n",
       "      <td>14.82</td>\n",
       "      <td>instock</td>\n",
       "      <td>2</td>\n",
       "      <td>classics</td>\n",
       "      <td>2022-05-05 15:36:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>little_women_(little_women_#1)</td>\n",
       "      <td>28.07</td>\n",
       "      <td>instock</td>\n",
       "      <td>4</td>\n",
       "      <td>classics</td>\n",
       "      <td>2022-05-05 15:36:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name product_price  \\\n",
       "0                                  the_secret_garden         15.08   \n",
       "1                                  the_metamorphosis         28.58   \n",
       "2                             the_pilgrim's_progress         50.26   \n",
       "3  the_hound_of_the_baskervilles_(sherlock_holmes...         14.82   \n",
       "4                     little_women_(little_women_#1)         28.07   \n",
       "\n",
       "  product_stock product_avaliation product_category     scrapy_datetime  \n",
       "0       instock                  4         classics 2022-05-05 15:36:34  \n",
       "1       instock                  1         classics 2022-05-05 15:36:34  \n",
       "2       instock                  2         classics 2022-05-05 15:36:34  \n",
       "3       instock                  2         classics 2022-05-05 15:36:34  \n",
       "4       instock                  4         classics 2022-05-05 15:36:34  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://books.toscrape.com/catalogue/category/books/classics_6'\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36 OPR/37.0.2178.54'}\n",
    "\n",
    "page = requests.get(url,headers = headers)\n",
    "\n",
    "soup= BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "products_page_inicial = soup.find('ol',class_='row')\n",
    "\n",
    "#colect name of book\n",
    "name_book =  soup.find_all('img',class_='thumbnail')\n",
    "\n",
    "#name of book\n",
    "product_name= [p.get('alt') for p in name_book ]\n",
    "\n",
    "#price of books\n",
    "price_regular= products_page_inicial.find_all('p',class_='price_color')\n",
    "product_price= [p.get_text() for p in price_regular]\n",
    "\n",
    "#product in stock\n",
    "stock= products_page_inicial.find_all('p',class_='instock availability')\n",
    "\n",
    "product_stock= [p.get('class')[0] for p in stock]\n",
    "\n",
    "#category\n",
    "\n",
    "list_category = soup.find('li',class_='active').get_text('Classics')\n",
    "    \n",
    "#product_category= [p.get_text() for p in list_category]\n",
    "\n",
    "#coletando link para fazer paginação\n",
    "\n",
    "#list_link=soup.find_all('article',class_='product_pod')\n",
    "\n",
    "#link_book= [p.a.get('href')[9:] for p in list_link]\n",
    "\n",
    "#avaliation o book\n",
    "star_of_book= soup.find_all('p', class_= 'star-rating')\n",
    "\n",
    "product_avaliation = [p.get('class')[1] for p in star_of_book]\n",
    "\n",
    "#making data\n",
    "data= pd.DataFrame([product_name,product_price,product_stock,product_avaliation]).T\n",
    "\n",
    "data.columns= ['product_name','product_price','product_stock','product_avaliation']\n",
    "\n",
    "data['product_category'] = list_category\n",
    "\n",
    "data['scrapy_datetime'] = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "\n",
    "##### cleaning the data ############\n",
    "\n",
    "#product_name\n",
    "\n",
    "data['product_name'] = data['product_name'].map(lambda x: x.lower().replace(' ','_') )\n",
    "\n",
    "#product price\n",
    "\n",
    "data['product_price']= data['product_price'].apply(lambda x: re.search('\\d+.\\d+',x).group(0))\n",
    "\n",
    "#product_stock\n",
    "\n",
    "data['product_avaliation']= data['product_avaliation'].map(lambda x: x.lower())\n",
    "\n",
    "#category\n",
    "data['product_category'] = data['product_category'].apply(lambda x: x.lower())\n",
    "\n",
    "#date\n",
    "data['scrapy_datetime']= pd.to_datetime(data['scrapy_datetime'],format= '%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "data['product_avaliation'] = data['product_avaliation'].apply(lambda x: x.replace('one','1').replace('two','2').\n",
    "                                                             replace('three','3').replace('four','4'))\n",
    "\n",
    "data_classic= data.copy(deep=True)\n",
    "\n",
    "data_classic.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a1cec0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#links = [link.get('href') for link in soup.find_all('a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f964d1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_stock</th>\n",
       "      <th>product_avaliation</th>\n",
       "      <th>product_category</th>\n",
       "      <th>scrapy_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mesaerion:_the_best_science_fiction_stories_18...</td>\n",
       "      <td>37.59</td>\n",
       "      <td>instock</td>\n",
       "      <td>1</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2022-05-05 15:40:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>join</td>\n",
       "      <td>35.67</td>\n",
       "      <td>instock</td>\n",
       "      <td>5</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2022-05-05 15:40:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>william_shakespeare's_star_wars:_verily,_a_new...</td>\n",
       "      <td>43.30</td>\n",
       "      <td>instock</td>\n",
       "      <td>4</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2022-05-05 15:40:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the_project</td>\n",
       "      <td>10.65</td>\n",
       "      <td>instock</td>\n",
       "      <td>1</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2022-05-05 15:40:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soft_apocalypse</td>\n",
       "      <td>26.12</td>\n",
       "      <td>instock</td>\n",
       "      <td>2</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2022-05-05 15:40:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name product_price  \\\n",
       "0  mesaerion:_the_best_science_fiction_stories_18...         37.59   \n",
       "1                                               join         35.67   \n",
       "2  william_shakespeare's_star_wars:_verily,_a_new...         43.30   \n",
       "3                                        the_project         10.65   \n",
       "4                                    soft_apocalypse         26.12   \n",
       "\n",
       "  product_stock product_avaliation product_category     scrapy_datetime  \n",
       "0       instock                  1  science fiction 2022-05-05 15:40:42  \n",
       "1       instock                  5  science fiction 2022-05-05 15:40:42  \n",
       "2       instock                  4  science fiction 2022-05-05 15:40:42  \n",
       "3       instock                  1  science fiction 2022-05-05 15:40:42  \n",
       "4       instock                  2  science fiction 2022-05-05 15:40:42  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ================Science Ficition =========##\n",
    "\n",
    "url = 'https://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html'\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36 OPR/37.0.2178.54'}\n",
    "\n",
    "page = requests.get(url,headers = headers)\n",
    "\n",
    "soup= BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "products_page_inicial = soup.find('ol',class_='row')\n",
    "\n",
    "#colect name of book\n",
    "name_book =  soup.find_all('img',class_='thumbnail')\n",
    "\n",
    "#name of book\n",
    "product_name= [p.get('alt') for p in name_book ]\n",
    "\n",
    "#price of books\n",
    "price_regular= products_page_inicial.find_all('p',class_='price_color')\n",
    "product_price= [p.get_text() for p in price_regular]\n",
    "\n",
    "#product in stock\n",
    "stock= products_page_inicial.find_all('p',class_='instock availability')\n",
    "\n",
    "product_stock= [p.get('class')[0] for p in stock]\n",
    "\n",
    "#category\n",
    "\n",
    "list_category = soup.find('li',class_='active').get_text('Science Ficition')\n",
    "    \n",
    "#product_category= [p.get_text() for p in list_category]\n",
    "\n",
    "#coletando link para fazer paginação\n",
    "\n",
    "#list_link=soup.find_all('article',class_='product_pod')\n",
    "\n",
    "#link_book= [p.a.get('href')[9:] for p in list_link]\n",
    "\n",
    "#avaliation o book\n",
    "star_of_book= soup.find_all('p', class_= 'star-rating')\n",
    "\n",
    "product_avaliation = [p.get('class')[1] for p in star_of_book]\n",
    "\n",
    "#making data\n",
    "data= pd.DataFrame([product_name,product_price,product_stock,product_avaliation]).T\n",
    "\n",
    "data.columns= ['product_name','product_price','product_stock','product_avaliation']\n",
    "\n",
    "data['product_category'] = list_category\n",
    "\n",
    "data['scrapy_datetime'] = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "\n",
    "##### cleaning the data ############\n",
    "\n",
    "#product_name\n",
    "\n",
    "data['product_name'] = data['product_name'].map(lambda x: x.lower().replace(' ','_') )\n",
    "\n",
    "#product price\n",
    "\n",
    "data['product_price']= data['product_price'].apply(lambda x: re.search('\\d+.\\d+',x).group(0))\n",
    "\n",
    "#product_stock\n",
    "\n",
    "data['product_avaliation']= data['product_avaliation'].map(lambda x: x.lower())\n",
    "\n",
    "#category\n",
    "data['product_category'] = data['product_category'].apply(lambda x: x.lower())\n",
    "\n",
    "#date\n",
    "data['scrapy_datetime']= pd.to_datetime(data['scrapy_datetime'],format= '%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "data['product_avaliation'] = data['product_avaliation'].apply(lambda x: x.replace('one','1').replace('two','2').\n",
    "                                                             replace('three','3').replace('four','4').\n",
    "                                                              replace('five','5'))\n",
    "\n",
    "data_science= data.copy(deep=True)\n",
    "\n",
    "data_science.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f572f183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_stock</th>\n",
       "      <th>product_avaliation</th>\n",
       "      <th>product_category</th>\n",
       "      <th>scrapy_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the_long_haul_(diary_of_a_wimpy_kid_#9)</td>\n",
       "      <td>44.07</td>\n",
       "      <td>instock</td>\n",
       "      <td>1</td>\n",
       "      <td>humor</td>\n",
       "      <td>2022-05-05 15:47:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>old_school_(diary_of_a_wimpy_kid_#10)</td>\n",
       "      <td>11.83</td>\n",
       "      <td>instock</td>\n",
       "      <td>5</td>\n",
       "      <td>humor</td>\n",
       "      <td>2022-05-05 15:47:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i_know_what_i'm_doing_--_and_other_lies_i_tell...</td>\n",
       "      <td>25.98</td>\n",
       "      <td>instock</td>\n",
       "      <td>4</td>\n",
       "      <td>humor</td>\n",
       "      <td>2022-05-05 15:47:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hyperbole_and_a_half:_unfortunate_situations,_...</td>\n",
       "      <td>14.75</td>\n",
       "      <td>instock</td>\n",
       "      <td>5</td>\n",
       "      <td>humor</td>\n",
       "      <td>2022-05-05 15:47:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dress_your_family_in_corduroy_and_denim</td>\n",
       "      <td>43.68</td>\n",
       "      <td>instock</td>\n",
       "      <td>3</td>\n",
       "      <td>humor</td>\n",
       "      <td>2022-05-05 15:47:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name product_price  \\\n",
       "0            the_long_haul_(diary_of_a_wimpy_kid_#9)         44.07   \n",
       "1              old_school_(diary_of_a_wimpy_kid_#10)         11.83   \n",
       "2  i_know_what_i'm_doing_--_and_other_lies_i_tell...         25.98   \n",
       "3  hyperbole_and_a_half:_unfortunate_situations,_...         14.75   \n",
       "4            dress_your_family_in_corduroy_and_denim         43.68   \n",
       "\n",
       "  product_stock product_avaliation product_category     scrapy_datetime  \n",
       "0       instock                  1            humor 2022-05-05 15:47:10  \n",
       "1       instock                  5            humor 2022-05-05 15:47:10  \n",
       "2       instock                  4            humor 2022-05-05 15:47:10  \n",
       "3       instock                  5            humor 2022-05-05 15:47:10  \n",
       "4       instock                  3            humor 2022-05-05 15:47:10  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ================ Humor =========##\n",
    "\n",
    "url = 'https://books.toscrape.com/catalogue/category/books/humor_30/index.html'\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36 OPR/37.0.2178.54'}\n",
    "\n",
    "page = requests.get(url,headers = headers)\n",
    "\n",
    "soup= BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "products_page_inicial = soup.find('ol',class_='row')\n",
    "\n",
    "#colect name of book\n",
    "name_book =  soup.find_all('img',class_='thumbnail')\n",
    "\n",
    "#name of book\n",
    "product_name= [p.get('alt') for p in name_book ]\n",
    "\n",
    "#price of books\n",
    "price_regular= products_page_inicial.find_all('p',class_='price_color')\n",
    "product_price= [p.get_text() for p in price_regular]\n",
    "\n",
    "#product in stock\n",
    "stock= products_page_inicial.find_all('p',class_='instock availability')\n",
    "\n",
    "product_stock= [p.get('class')[0] for p in stock]\n",
    "\n",
    "#category\n",
    "\n",
    "list_category = soup.find('li',class_='active').get_text('Humor')\n",
    "    \n",
    "#avaliation o book\n",
    "star_of_book= soup.find_all('p', class_= 'star-rating')\n",
    "\n",
    "product_avaliation = [p.get('class')[1] for p in star_of_book]\n",
    "\n",
    "#making data\n",
    "data= pd.DataFrame([product_name,product_price,product_stock,product_avaliation]).T\n",
    "\n",
    "data.columns= ['product_name','product_price','product_stock','product_avaliation']\n",
    "\n",
    "data['product_category'] = list_category\n",
    "\n",
    "data['scrapy_datetime'] = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "\n",
    "##### cleaning the data ############\n",
    "\n",
    "#product_name\n",
    "\n",
    "data['product_name'] = data['product_name'].map(lambda x: x.lower().replace(' ','_') )\n",
    "\n",
    "#product price\n",
    "\n",
    "data['product_price']= data['product_price'].apply(lambda x: re.search('\\d+.\\d+',x).group(0))\n",
    "\n",
    "#product_stock\n",
    "\n",
    "data['product_avaliation']= data['product_avaliation'].map(lambda x: x.lower())\n",
    "\n",
    "#category\n",
    "data['product_category'] = data['product_category'].apply(lambda x: x.lower())\n",
    "\n",
    "#date\n",
    "data['scrapy_datetime']= pd.to_datetime(data['scrapy_datetime'],format= '%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "data['product_avaliation'] = data['product_avaliation'].apply(lambda x: x.replace('one','1').replace('two','2').\n",
    "                                                             replace('three','3').replace('four','4').\n",
    "                                                              replace('five','5'))\n",
    "\n",
    "data_humor = data.copy(deep=True)\n",
    "\n",
    "data_humor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "59ce432c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_stock</th>\n",
       "      <th>product_avaliation</th>\n",
       "      <th>product_category</th>\n",
       "      <th>scrapy_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the_dirty_little_secrets_of_getting_your_dream...</td>\n",
       "      <td>33.34</td>\n",
       "      <td>instock</td>\n",
       "      <td>4</td>\n",
       "      <td>business</td>\n",
       "      <td>2022-05-05 15:51:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the_third_wave:_an_entrepreneurâs_vision_of_...</td>\n",
       "      <td>12.61</td>\n",
       "      <td>instock</td>\n",
       "      <td>5</td>\n",
       "      <td>business</td>\n",
       "      <td>2022-05-05 15:51:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_10%_entrepreneur:_live_your_startup_dream_...</td>\n",
       "      <td>27.55</td>\n",
       "      <td>instock</td>\n",
       "      <td>3</td>\n",
       "      <td>business</td>\n",
       "      <td>2022-05-05 15:51:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shoe_dog:_a_memoir_by_the_creator_of_nike</td>\n",
       "      <td>23.99</td>\n",
       "      <td>instock</td>\n",
       "      <td>2</td>\n",
       "      <td>business</td>\n",
       "      <td>2022-05-05 15:51:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>made_to_stick:_why_some_ideas_survive_and_othe...</td>\n",
       "      <td>38.85</td>\n",
       "      <td>instock</td>\n",
       "      <td>5</td>\n",
       "      <td>business</td>\n",
       "      <td>2022-05-05 15:51:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name product_price  \\\n",
       "0  the_dirty_little_secrets_of_getting_your_dream...         33.34   \n",
       "1  the_third_wave:_an_entrepreneurâs_vision_of_...         12.61   \n",
       "2  the_10%_entrepreneur:_live_your_startup_dream_...         27.55   \n",
       "3          shoe_dog:_a_memoir_by_the_creator_of_nike         23.99   \n",
       "4  made_to_stick:_why_some_ideas_survive_and_othe...         38.85   \n",
       "\n",
       "  product_stock product_avaliation product_category     scrapy_datetime  \n",
       "0       instock                  4         business 2022-05-05 15:51:30  \n",
       "1       instock                  5         business 2022-05-05 15:51:30  \n",
       "2       instock                  3         business 2022-05-05 15:51:30  \n",
       "3       instock                  2         business 2022-05-05 15:51:30  \n",
       "4       instock                  5         business 2022-05-05 15:51:30  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ================ Bussines =========##\n",
    "\n",
    "url = 'https://books.toscrape.com/catalogue/category/books/business_35/index.html'\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36 OPR/37.0.2178.54'}\n",
    "\n",
    "page = requests.get(url,headers = headers)\n",
    "\n",
    "soup= BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "products_page_inicial = soup.find('ol',class_='row')\n",
    "\n",
    "#colect name of book\n",
    "name_book =  soup.find_all('img',class_='thumbnail')\n",
    "\n",
    "#name of book\n",
    "product_name= [p.get('alt') for p in name_book ]\n",
    "\n",
    "#price of books\n",
    "price_regular= products_page_inicial.find_all('p',class_='price_color')\n",
    "product_price= [p.get_text() for p in price_regular]\n",
    "\n",
    "#product in stock\n",
    "stock= products_page_inicial.find_all('p',class_='instock availability')\n",
    "\n",
    "product_stock= [p.get('class')[0] for p in stock]\n",
    "\n",
    "#category\n",
    "\n",
    "list_category = soup.find('li',class_='active').get_text('Bussines')\n",
    "    \n",
    "#avaliation o book\n",
    "star_of_book= soup.find_all('p', class_= 'star-rating')\n",
    "\n",
    "product_avaliation = [p.get('class')[1] for p in star_of_book]\n",
    "\n",
    "#making data\n",
    "data= pd.DataFrame([product_name,product_price,product_stock,product_avaliation]).T\n",
    "\n",
    "data.columns= ['product_name','product_price','product_stock','product_avaliation']\n",
    "\n",
    "data['product_category'] = list_category\n",
    "\n",
    "data['scrapy_datetime'] = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "\n",
    "##### cleaning the data ############\n",
    "\n",
    "#product_name\n",
    "\n",
    "data['product_name'] = data['product_name'].map(lambda x: x.lower().replace(' ','_') )\n",
    "\n",
    "#product price\n",
    "\n",
    "data['product_price']= data['product_price'].apply(lambda x: re.search('\\d+.\\d+',x).group(0))\n",
    "\n",
    "#product_stock\n",
    "\n",
    "data['product_avaliation']= data['product_avaliation'].map(lambda x: x.lower())\n",
    "\n",
    "#category\n",
    "data['product_category'] = data['product_category'].apply(lambda x: x.lower())\n",
    "\n",
    "#date\n",
    "data['scrapy_datetime']= pd.to_datetime(data['scrapy_datetime'],format= '%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "data['product_avaliation'] = data['product_avaliation'].apply(lambda x: x.replace('one','1').replace('two','2').\n",
    "                                                             replace('three','3').replace('four','4').\n",
    "                                                              replace('five','5'))\n",
    "\n",
    "data_bussines = data.copy(deep=True)\n",
    "\n",
    "data_bussines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "aab3b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the datas\n",
    "data_books= pd.concat([data_classic,data_science,data_bussines,data_humor]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a5743ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the salve the data to csv\n",
    "\n",
    "data_books.to_csv('data_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e3bbe0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex = '/{1}(.+\\w+)/'\n",
    "#regex= '/{1}(.+?)/index.html'\n",
    "\n",
    "#for i in links:\n",
    "    #if pd.notnull(links):\n",
    "        #print(re.search(regex, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafbeeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cec0000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://books.toscrape.com/catalogue/the-secret-garden_413/index.html\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'get_text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m  product_list \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m,class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontainer-fluid page\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m  \u001b[38;5;66;03m#number of Availability of book\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# product_availabilty= product_list.find_all('td')[5].string[8:-10].replace('(','')\u001b[39;00m\n\u001b[1;32m     19\u001b[0m  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m  data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteste\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mproduct_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mclass_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprice_color\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text\u001b[49m()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÂ£\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documentos/repos/ds_ao_dev/dsaodev/lib/python3.8/site-packages/bs4/element.py:2253\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   2252\u001b[0m     \u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   2254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[1;32m   2255\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'get_text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36 OPR/37.0.2178.54'}\n",
    "    \n",
    "#API Requests\n",
    "for i in range(len(data)):\n",
    "    \n",
    "    \n",
    "    url = 'https://books.toscrape.com/catalogue/'+ data.loc[i,'link_book']\n",
    "    print(url)\n",
    "    page = requests.get( url, headers=headers )\n",
    "\n",
    "    #Beautifull Souo object\n",
    "    soup= BeautifulSoup(page.text,'html.parser')\n",
    "    \n",
    "    product_list = soup.find('div',class_='container-fluid page')\n",
    "    \n",
    "    #number of Availability of book\n",
    "\n",
    "   # product_availabilty= product_list.find_all('td')[5].string[8:-10].replace('(','')\n",
    "    #\n",
    "    data['teste'] = product_list.find_all('p',class_='price_color').get_text().replace('Â£','')\n",
    "   \n",
    "    #print(product_availabilty)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61aa6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f6f1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb33bc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_stock</th>\n",
       "      <th>link_book</th>\n",
       "      <th>product_category</th>\n",
       "      <th>scrapy_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Secret Garden</td>\n",
       "      <td>15.08</td>\n",
       "      <td>In stock</td>\n",
       "      <td>the-secret-garden_413/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Metamorphosis</td>\n",
       "      <td>28.58</td>\n",
       "      <td>In stock</td>\n",
       "      <td>the-metamorphosis_409/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Pilgrim's Progress</td>\n",
       "      <td>50.26</td>\n",
       "      <td>In stock</td>\n",
       "      <td>the-pilgrims-progress_353/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Hound of the Baskervilles (Sherlock Holmes...</td>\n",
       "      <td>14.82</td>\n",
       "      <td>In stock</td>\n",
       "      <td>the-hound-of-the-baskervilles-sherlock-holmes-...</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Women (Little Women #1)</td>\n",
       "      <td>28.07</td>\n",
       "      <td>In stock</td>\n",
       "      <td>little-women-little-women-1_331/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>32.49</td>\n",
       "      <td>In stock</td>\n",
       "      <td>gone-with-the-wind_324/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Candide</td>\n",
       "      <td>58.63</td>\n",
       "      <td>In stock</td>\n",
       "      <td>candide_316/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>57.22</td>\n",
       "      <td>In stock</td>\n",
       "      <td>animal-farm_313/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>17.73</td>\n",
       "      <td>In stock</td>\n",
       "      <td>wuthering-heights_307/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Picture of Dorian Gray</td>\n",
       "      <td>29.70</td>\n",
       "      <td>In stock</td>\n",
       "      <td>the-picture-of-dorian-gray_270/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Complete Stories and Poems (The Works of E...</td>\n",
       "      <td>26.78</td>\n",
       "      <td>In stock</td>\n",
       "      <td>the-complete-stories-and-poems-the-works-of-ed...</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Beowulf</td>\n",
       "      <td>38.35</td>\n",
       "      <td>In stock</td>\n",
       "      <td>beowulf_126/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>And Then There Were None</td>\n",
       "      <td>35.01</td>\n",
       "      <td>In stock</td>\n",
       "      <td>and-then-there-were-none_119/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Story of Hong Gildong</td>\n",
       "      <td>43.19</td>\n",
       "      <td>In stock</td>\n",
       "      <td>the-story-of-hong-gildong_84/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Little Prince</td>\n",
       "      <td>45.42</td>\n",
       "      <td>In stock</td>\n",
       "      <td>the-little-prince_72/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sense and Sensibility</td>\n",
       "      <td>37.46</td>\n",
       "      <td>In stock</td>\n",
       "      <td>sense-and-sensibility_49/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Of Mice and Men</td>\n",
       "      <td>47.11</td>\n",
       "      <td>In stock</td>\n",
       "      <td>of-mice-and-men_37/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Emma</td>\n",
       "      <td>32.93</td>\n",
       "      <td>In stock</td>\n",
       "      <td>emma_17/index.html</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Alice in Wonderland (Alice's Adventures in Won...</td>\n",
       "      <td>55.53</td>\n",
       "      <td>In stock</td>\n",
       "      <td>alice-in-wonderland-alices-adventures-in-wonde...</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2022-04-21-17-22-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classics</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         product_name product_price  \\\n",
       "0                                   The Secret Garden         15.08   \n",
       "1                                   The Metamorphosis         28.58   \n",
       "2                              The Pilgrim's Progress         50.26   \n",
       "3   The Hound of the Baskervilles (Sherlock Holmes...         14.82   \n",
       "4                      Little Women (Little Women #1)         28.07   \n",
       "5                                  Gone with the Wind         32.49   \n",
       "6                                             Candide         58.63   \n",
       "7                                         Animal Farm         57.22   \n",
       "8                                   Wuthering Heights         17.73   \n",
       "9                          The Picture of Dorian Gray         29.70   \n",
       "10  The Complete Stories and Poems (The Works of E...         26.78   \n",
       "11                                            Beowulf         38.35   \n",
       "12                           And Then There Were None         35.01   \n",
       "13                          The Story of Hong Gildong         43.19   \n",
       "14                                  The Little Prince         45.42   \n",
       "15                              Sense and Sensibility         37.46   \n",
       "16                                    Of Mice and Men         47.11   \n",
       "17                                               Emma         32.93   \n",
       "18  Alice in Wonderland (Alice's Adventures in Won...         55.53   \n",
       "0                                                 NaN           NaN   \n",
       "\n",
       "   product_stock                                          link_book  \\\n",
       "0       In stock                   the-secret-garden_413/index.html   \n",
       "1       In stock                   the-metamorphosis_409/index.html   \n",
       "2       In stock               the-pilgrims-progress_353/index.html   \n",
       "3       In stock  the-hound-of-the-baskervilles-sherlock-holmes-...   \n",
       "4       In stock         little-women-little-women-1_331/index.html   \n",
       "5       In stock                  gone-with-the-wind_324/index.html   \n",
       "6       In stock                             candide_316/index.html   \n",
       "7       In stock                         animal-farm_313/index.html   \n",
       "8       In stock                   wuthering-heights_307/index.html   \n",
       "9       In stock          the-picture-of-dorian-gray_270/index.html   \n",
       "10      In stock  the-complete-stories-and-poems-the-works-of-ed...   \n",
       "11      In stock                             beowulf_126/index.html   \n",
       "12      In stock            and-then-there-were-none_119/index.html   \n",
       "13      In stock            the-story-of-hong-gildong_84/index.html   \n",
       "14      In stock                    the-little-prince_72/index.html   \n",
       "15      In stock                sense-and-sensibility_49/index.html   \n",
       "16      In stock                      of-mice-and-men_37/index.html   \n",
       "17      In stock                                 emma_17/index.html   \n",
       "18      In stock  alice-in-wonderland-alices-adventures-in-wonde...   \n",
       "0            NaN                                                NaN   \n",
       "\n",
       "   product_category      scrapy_datetime  \n",
       "0          Classics  2022-04-21-17-22-36  \n",
       "1          Classics  2022-04-21-17-22-36  \n",
       "2          Classics  2022-04-21-17-22-36  \n",
       "3          Classics  2022-04-21-17-22-36  \n",
       "4          Classics  2022-04-21-17-22-36  \n",
       "5          Classics  2022-04-21-17-22-36  \n",
       "6          Classics  2022-04-21-17-22-36  \n",
       "7          Classics  2022-04-21-17-22-36  \n",
       "8          Classics  2022-04-21-17-22-36  \n",
       "9          Classics  2022-04-21-17-22-36  \n",
       "10         Classics  2022-04-21-17-22-36  \n",
       "11         Classics  2022-04-21-17-22-36  \n",
       "12         Classics  2022-04-21-17-22-36  \n",
       "13         Classics  2022-04-21-17-22-36  \n",
       "14         Classics  2022-04-21-17-22-36  \n",
       "15         Classics  2022-04-21-17-22-36  \n",
       "16         Classics  2022-04-21-17-22-36  \n",
       "17         Classics  2022-04-21-17-22-36  \n",
       "18         Classics  2022-04-21-17-22-36  \n",
       "0          Classics                  NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PROCESSO FOR (UTILIZAR NO FUTURO)\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36 OPR/37.0.2178.54'}\n",
    "    \n",
    "#API Requests\n",
    "for i in range(len(data)):\n",
    "    \n",
    "    \n",
    "    url = 'https://books.toscrape.com/catalogue/'+ data.loc[i,'link_book']\n",
    "    \n",
    "    page = requests.get( url, headers=headers )\n",
    "\n",
    "    #Beautifull Souo object\n",
    "    soup= BeautifulSoup(page.text,'html.parser')\n",
    "        \n",
    "    #\n",
    "    #list_category= soup.find('a',href='../category/books/classics_6/index.html')\n",
    "    \n",
    "    #product_category= [p.get_text() for p in list_category]\n",
    "   \n",
    "    #number of Availability of book\n",
    "\n",
    "    product_availabilty= product_list.find_all('td')[5].string[8:-10].replace('(','')\n",
    "    \n",
    "    df_new = pd.DataFrame(product_availabilty).T\n",
    "    \n",
    "    df_new.columns= ['product_availabilty']   \n",
    "    \n",
    "    df_merge= pd.concat([data,df_new],axis=0)\n",
    "    \n",
    "df_merge\n",
    "\n",
    "\n",
    "    #terceira parte/ observar a coleta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0882254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classics']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f46c0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alice in Wonderland (Alice's Adventures in Wonderland #1)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a727aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
